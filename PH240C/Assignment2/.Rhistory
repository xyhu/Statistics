sumLogFac = sum(log(factorial(data1)))
sumX
sumLogFac
log(factorial(data1))
factorial(data1)
data1 = c(1,2,6,2,3,3,2,3,2,1,5,2,2,4,2,0,2,1,2,1)
lambda = seq(0,10, length.out = 1000)
loglik = function(lambda,data){
n = length(data)
sumX = sum(data)
sumLogFac = sum(log(factorial(data)))
loglik = sumX*log(lambda) - n*lambda - sumLogFac
return(loglik)
}
ll = loglik(lambda, data1)
plot(ll ~ lambda, main="Log-likelihood function for poisson distribution", xlab=expression(lambda),
ylab = "Log-likelihood function")
plot(ll ~ lambda, main="Log-likelihood function for poisson distribution", xlab=expression(lambda),
ylab = "Log-likelihood function", lty ="l")
plot(ll ~ lambda, main="Log-likelihood function for poisson distribution", xlab=expression(lambda),
ylab = "Log-likelihood function", type ="l")
mean(data1)
optimize(loglik, interval = c(0,4), data1)
optimize(loglik, interval = c(0,4), data1, maximum =TRUE)
t = c(1,2,3)
prod(t)
exp(1)
lik = function(data, lambda){
sumX = sum(data)
n = length(data)
facProd = prod(factorial(data))
lik = (lambda^sumX * exp(-n*lambda)) / facProd
return(lik)
}
l = lik(data1,lambda)
plot(ll ~ lambda, main="Likelihood function for poisson distribution", xlab=expression(lambda),
ylab = "Likelihood function", type ="l")
plot(l ~ lambda, main="Likelihood function for poisson distribution", xlab=expression(lambda),
ylab = "Likelihood function", type ="l")
loglik_t = function(data, theta){
sumX = sum(data)
n = length(data)
sumLogFac = sum(log(factorial(data)))
loglik = sumX*theta - n*exp(theta) - sumLogFac
return(loglik)
}
optimize(loglik_t, interval = c(0,4), data1, maximum =TRUE)
theta = log(lambda)
ll_t = loglik_t(data1,theta)
ll_t
plot(ll_t~theta)
optimize(loglik_t, interval = c(0,4), data1, maximum =TRUE)
optimize(loglik_t, interval = c(-1,2), data1, maximum =TRUE)
loglik_t
length(ll_t)
loglik_t = function(data, theta){
sumX = sum(data)
n = length(data)
sumLogFac = sum(log(factorial(data)))
loglik_t = sumX*theta - n*exp(theta) - sumLogFac
return(loglik_t)
}
optimize(loglik_t, interval = c(-1,2), data1, maximum =TRUE)
log(2.3)
loglik_t = function(theta, data){
sumX = sum(data)
n = length(data)
sumLogFac = sum(log(factorial(data)))
loglik_t = sumX*theta - n*exp(theta) - sumLogFac
return(loglik_t)
}
optimize(loglik_t, interval = c(-1,2), data1, maximum =TRUE)
plot(ll_t~theta, main="Log-likelihood function for poisson distribution-different parametrization", xlab=expression(theta),
ylab = expression(paste("Log-likelihood function for ",theta), type ="l")
)
plot(ll_t~theta, main="Log-likelihood function for poisson distribution-different parametrization", xlab=expression(theta),
ylab = expression(paste("Log-likelihood function for ",theta)), type ="l")
plot(ll_t~theta, main="Log-likelihood function for poisson distribution-different parametrization", xlab=expression(theta),ylab = expression(paste("Log-likelihood function for ",theta)), type ="l", cex = 0.5)
plot(ll_t~theta, main="Log-likelihood function for poisson distribution-different parametrization", xlab=expression(theta),ylab = expression(paste("Log-likelihood function for ",theta)), type ="l", cex = 1)
data2 = c(0.15812, 0.30070, 0.48016, 0.49813, 0.20042, 0.26716, 0.80124,
0.10914, 0.57169, 0.83686, 1.57027, 0.10458, 0.58490, 1.14454,
0.61595, 0.28155, 0.13236, 0.36252, 0.08614, 0.27907, 0.46010,
0.03824, 0.76581, 0.30369, 0.42404, 0.57530, 0.26987, 0.22416,
0.07673, 1.09659)
a = seq(0,10,1000)
lam = seq(0,10,1000)
loglik2 = function(a, lam, data){
n = length(data)
# gammar of alpha
ga = factorial(a-1)
sumY = sum(data)
sumLog = sum(log(data))
loglik2 = -n*log(ga) + n*a*log(lam) + (a-1)*sumLog - lam*sumY
return(loglik2)
}
ll2 = loglik2(a, lam, data2)
ll2
sumY
sumY = sum(data)
sumY = sum(data2)
ga = factorial(a-1)
gammar(a)
gamma(a)
a
a = seq(0,10,length.out=1000)
lam = seq(0,10,length.out=1000)
ll2 = loglik2(a, lam, data2)
factorial(a)
factorial(a-1)
a = seq(0.0001,10,length.out=1000)
lam = seq(0.0001,10,length.out=1000)
ll2 = loglik2(a, lam, data2)
image(x=a,y=lam,z=ll2)
ll2
ll2 = outer(a,lam,loglik2,data2)
ll2
dim(ll2)
image(a,lam,ll2)
a = seq(0.0001,10,length.out=500)
lam = seq(0.0001,10,length.out=500)
ll2 = outer(a,lam,loglik2,data2)
persp(a,lam,ll2)
persp(a,lam,ll2,theta=30,phi=30,ticktype="detailed")
contour(a,lam,ll2,nlevels=12)
image(a,lam,ll2,)
pars = c("a":a,"lam":lam)
pars = c(a=a,lam=lam)
class(pars)
pars[[a]]
pars[a]
persp(a,lam,ll2,theta=30,phi=-30,ticktype="detailed")
persp(a,lam,ll2,theta=10,phi=10,ticktype="detailed")
persp(a,lam,ll2,ticktype="detailed")
persp(a,lam,ll2,ticktype="detailed", col="yellow")
negloglik2 = function(pars, data){
a = pars[1]
lam = pars[2]
n = length(data)
# gammar of alpha
ga = factorial(a-1)
sumY = sum(data)
sumLog = sum(log(data))
loglik2 = -(-n*log(ga) + n*a*log(lam) + (a-1)*sumLog - lam*sumY)
return(loglik2)
}
optim(c(0,0), negloglik2, data2)
optim(c(0,0), negloglik2, data=data2)
optim(c(0.001,0.001), negloglik2, data=data2)
optim(c(1,1), negloglik2, data=data2)
setwd("~/Documents/ZhengShi/Berkeley/Courses/PH240C/Assignment/Assignment2")
ls = read.table("learning.txt")
head(ls)
ts = read.table("test.txt")
head(ts)
D <- 1:6
fitLm <- vector("list", length(D))
YhatLm <- matrix(NA, N, length(D))
LSRiskLm <- TSRiskLm <- rep(NA, length(D))
W <- NULL
for(d in 1:length(D))
{
W <- cbind(W, w^D[d])
fitLm[[d]] <- lm(y ~ W, subset=ls)
YhatLm[,d] <- W%*%matrix(fitLm[[d]]$coef[-1],D[d],1) + fitLm[[d]]$coeff[1]
LSRiskLm[d] <- mean(fitLm[[d]]$residuals^2)
TSRiskLm[d] <- mean((YhatLm[ts,d] - y[ts])^2, na.rm=TRUE)
}
D <- 1:6
D
fitLm <- vector("list", length(D))
fitLm
YhatLm <- matrix(NA, nrow(ls), length(D))
YhatLm
LSRiskLm <- TSRiskLm <- rep(NA, length(D))
LSRisklm
TSRisklm
LSRiskLm = rep(NA, length(D))
LSRisklm
LSRiskLm <- rep(NA, length(D))
LSRiskLm
TSRiskLm = rep(NA, length(D))
TSRiskLm
w = ls$W
head(ls)
for(d in 1:length(D))
{
W <- cbind(W, w^D[d])
fitLm[[d]] <- lm(y ~ W, subset=ls)
YhatLm[,d] <- W%*%matrix(fitLm[[d]]$coef[-1],D[d],1) + fitLm[[d]]$coeff[1]
LSRiskLm[d] <- mean(fitLm[[d]]$residuals^2)
TSRiskLm[d] <- mean((YhatLm[ts,d] - y[ts])^2, na.rm=TRUE)
}
y = ls$Y
for(d in 1:length(D))
{
W <- cbind(W, w^D[d])
fitLm[[d]] <- lm(y ~ W, subset=ls)
YhatLm[,d] <- W%*%matrix(fitLm[[d]]$coef[-1],D[d],1) + fitLm[[d]]$coeff[1]
LSRiskLm[d] <- mean(fitLm[[d]]$residuals^2)
TSRiskLm[d] <- mean((YhatLm[ts,d] - y[ts])^2, na.rm=TRUE)
}
YhatLm <- matrix(NA, nrow(ls)+nrow(ts), length(D))
YhatLm <- matrix(NA, nrow(ts), length(D))
w = ls$W
y = ls$Y
W <- NULL
for(d in 1:length(D))
{
W <- cbind(W, w^D[d])
fitLm[[d]] <- lm(Y ~ W, data=ls)
YhatLm[,d] <- predict(fitLm[[d]], ts$W)
LSRiskLm[d] <- mean(fitLm[[d]]$residuals^2)
TSRiskLm[d] <- mean((YhatLm - ts$Y)^2, na.rm=TRUE)
}
fitLm[[1]]
ls = read.table("learning.txt")
ts = read.table("test.txt")
D <- 1:6
fitLm <- vector("list", length(D))
YhatLm <- matrix(NA, nrow(ts), length(D))
LSRiskLm = rep(NA, length(D))
TSRiskLm = rep(NA, length(D))
w.ls = ls$W
w.ts = ts$W
W.ls = NULL
W.ts = NULL
for(d in 1:length(D))
{
W.ls = cbind(W.ls, w.ls^D[d])
W.ts = cbind(W.ts, w.ts^D[d] )
fitLm[[d]] <- lm(Y ~ W, data=ls)
YhatLm[,d] <- predict(fitLm[[d]], W.ts)
LSRiskLm[d] <- mean(fitLm[[d]]$residuals^2)
TSRiskLm[d] <- mean((YhatLm - ts$Y)^2, na.rm=TRUE)
}
class(ls)
for(d in 1:length(D))
{
W.ls = cbind(W.ls, w.ls^D[d])
W.ts = cbind(W.ts, w.ts^D[d] )
fitLm[[d]] <- lm(Y ~ W, data=ls)
YhatLm[,d] <- predict(fitLm[[d]], as.data.frame(W.ts))
LSRiskLm[d] <- mean(fitLm[[d]]$residuals^2)
TSRiskLm[d] <- mean((YhatLm - ts$Y)^2, na.rm=TRUE)
}
colnames(ls)
for(d in 1:length(D))
{
W.ls = cbind(W.ls, w.ls^D[d])
W.ts = cbind(W.ts, w.ts^D[d] )
fitLm[[d]] <- lm(ls$Y ~ W.ls)
YhatLm[,d] <- predict(fitLm[[d]], as.data.frame(W.ts))
LSRiskLm[d] <- mean(fitLm[[d]]$residuals^2)
TSRiskLm[d] <- mean((YhatLm - ts$Y)^2, na.rm=TRUE)
}
warnings()
w.ls = ls$W
w.ts = ts$W
W.ls = NULL
W.ts = NULL
length(w.ls)
length(w.ts)
d = 1
W.ls = cbind(W.ls, w.ls^D[d])
W.ts = cbind(W.ts, w.ts^D[d] )
dim(W.ls)
dim(W.ts)
fitLm[[d]] <- lm(ls$Y ~ W.ls)
lm(ls$Y~ls$W)
lm(ls$Y~W.ls)
length(YhatLm)
dim(YhatLm)
YhatLm[,d] <- predict(fitLm[[d]], as.data.frame(W.ts))
YhatLm[,1]
YhatLm[,d] <- predict(fitLm[[d]], as.data.frame(W.ls=W.ts))
YhatLm[,d] <- predict(fitLm[[d]], data.frame(W.ls=W.ts))
fitLm[[d]]$coef
class(fitLm[[d]]$coef)
dim(fitLm[[d]]$coef)
fitLm[[d]]$coef[1]
dim(W.ts)
W.ts = rep(1,nrow(ts))
W.ts = cbind(W.ts, w.ts^D[d] )
dim(W.ts)
head(W.ts)
head(ts$W)
dim(as.matrix(fitLm[[d]]$coef))
YhatLm[,d] <- W.ts %*% fitLm[[d]]$coef
YhatLm[,6]
D <- 1:6
fitLm <- vector("list", length(D))
YhatLm <- matrix(NA, nrow(ts), length(D))
YhatLm
nrow(ts)
ls = read.table("learning.txt")
ts = read.table("test.txt")
YhatLm <- matrix(NA, nrow(ts), length(D))
LSRiskLm = rep(NA, length(D))
TSRiskLm = rep(NA, length(D))
w.ls = ls$W
w.ts = ts$W
W.ls = NULL
W.ts = rep(1,nrow(ts))
d =1
W.ls = cbind(W.ls, w.ls^D[d])
W.ts = cbind(W.ts, w.ts^D[d] )
head(W.ls)
head(W.ts)
fitLm[[d]] <- lm(ls$Y ~ W.ls)
fitLm[[1]]
YhatLm[,d] <- W.ts %*% fitLm[[d]]$coef
head(YhatLm[,1])
1.062 + -0.9988294*2.989
1.062 + -0.9955617*2.989
1.062 -0.9955617*2.989
1.062 + -0.9980670*2.989
YhatLm[,d] <- W.ts %*% matrix(fitLm[[d]]$coef,1,2)
as.matrix(fitLm[[d]]$coef)
YhatLm[,d] <- W.ts %*% as.matrix(fitLm[[d]]$coef)
head(YhatLm[,1])
1.061531 -0.9980670*2.988832
LSRiskLm[d] <- mean(fitLm[[d]]$residuals^2)
TSRiskLm[d] <- mean((YhatLm - ts$Y)^2, na.rm=TRUE)
for(d in 1:length(D))
{
W.ls = cbind(W.ls, w.ls^D[d])
W.ts = cbind(W.ts, w.ts^D[d] )
fitLm[[d]] <- lm(ls$Y ~ W.ls)
YhatLm[,d] <- W.ts %*% as.matrix(fitLm[[d]]$coef)
LSRiskLm[d] <- mean(fitLm[[d]]$residuals^2)
TSRiskLm[d] <- mean((YhatLm - ts$Y)^2, na.rm=TRUE)
}
fitLm[[1]]$fitted
plot(ls$W, ls$Y, xlim=c(-1.5, 1.5), ylim=c(-3, 3),
xlab="W", ylab="Y", main="Mystery model: lm fits, Y ~ 1 + W + ... + W^D")
max(ls$Y)
min(ls$Y)
plot(ls$W, ls$Y, xlim=c(-1.5, 1.5), ylim=c(-4, 6),
xlab="W", ylab="Y", main="Mystery model: lm fits, Y ~ 1 + W + ... + W^D")
matplot(ls$W, YhatLm.ls, type="l", lty=1:length(D), lwd=2,
col=1:length(D), add=TRUE)
D = 1:6
# create an empty list to store model for later
fitLm = vector("list", length(D))
# create an empty matrix to store fitted Y for training set
YhatLm.ts = matrix(NA, nrow(ts), length(D))
# create an empty matrix to store fitted Y for learning set
YhatLm.ls = matrix(NA, nrow(ls), length(D))
# create vectors of length(D) to store LS risk and TS risk for each model
LSRiskLm = rep(NA, length(D))
TSRiskLm = rep(NA, length(D))
w.ls = ls$W
w.ts = ts$W
W.ls = NULL
W.ts = rep(1,nrow(ts))
for(d in 1:length(D))
{
W.ls = cbind(W.ls, w.ls^D[d])
W.ts = cbind(W.ts, w.ts^D[d] )
fitLm[[d]] = lm(ls$Y ~ W.ls)
YhatLm.ts[,d] = W.ts %*% as.matrix(fitLm[[d]]$coef)
YhatLm.ls[,d] = fitLm[[d]]$fitted
LSRiskLm[d] = mean(fitLm[[d]]$residuals^2)
TSRiskLm[d] = mean((YhatLm.ts - ts$Y)^2, na.rm=TRUE)
}
matplot(ls$W, YhatLm.ls, type="l", lty=1:length(D), lwd=2,
col=1:length(D), add=TRUE)
legend("topleft", paste("D=",D,sep=""), lty=1:length(D),
lwd=2, col=1:length(D))
legend("topleft", paste("D=",D,sep=""), lty=1:length(D),
lwd=2, col=1:length(D), cex = 0.5)
plot(ls$W, ls$Y, xlim=c(-1.5, 1.5), ylim=c(-4, 6),
xlab="W", ylab="Y", main="Mystery model: lm fits, Y ~ 1 + W + ... + W^D")
matplot(ls$W, YhatLm.ls, type="l", lty=1:length(D), lwd=2,
col=1:length(D), add=TRUE)
legend("topleft", paste("D=",D,sep=""), lty=1:length(D),
lwd=2, col=1:length(D), cex = 0.5)
matplot(D, cbind(LSRiskLm,TSRiskLm), ylim=c(0.1, 0.55),
xlab="D", ylab="Risk", type="p", pch=19, col=2:3, cex=1.5,
main="Mystery model: Learning and test set risk for lm fits, Y ~ 1 + W + ... + W^D")
legend("topright", c("LS risk", "TS risk"), pch=19, col=2:3, cex=1.5)
TSRiskLm
LSRiskLm
matplot(D, cbind(LSRiskLm,TSRiskLm), ylim=c(0.1, 1),
xlab="D", ylab="Risk", type="p", pch=19, col=2:3, cex=1.5,
main="Mystery model: Learning and test set risk for lm fits, Y ~ 1 + W + ... + W^D")
legend("topright", c("LS risk", "TS risk"), pch=19, col=2:3, cex=1.5)
matplot(D, cbind(LSRiskLm,TSRiskLm), ylim=c(0.1, 1),
xlab="D", ylab="Risk", type="p", pch=19, col=2:3, cex=1.5,
main="Mystery model: Learning and test set risk for lm fits, Y ~ 1 + W + ... + W^D")
legend("topright", c("LS risk", "TS risk"), pch=19, col=2:3, cex=1)
span <- c(0.075, 0.1, 0.5, 0.9, 2)
YhatLoess <- matrix(NA, nrow(ls), length(span))
LSRiskLoess <- TSRiskLoess <- rep(NA,length(span))
j = 1
fit <- loess(Y ~ W, span=span[j], data=ls)
fit
YhatLoess[,j] <- fit$fitted
head(YhatLoess)
LSRiskLoess[j] <- mean(fit$residuals^2)
LSRiskLoes[j]
LSRiskLoess[j]
pred <- predict(fit,data.frame(w=w[ts]))
pred <- predict(fit,data.frame(ts$W))
ts$W
pred <- predict(fit,data.frame(W=ts$W))
pred
TSRiskLoess[j] <- mean((pred-ts$Y)^2, na.rm=TRUE)
plot(ls$W, ls$Y, xlim=c(-1.5, 1.5), ylim=c(-4, 6), xlab="W", ylab="Y",
main=paste("Mystery model: loess fits, span=", deparse(span), sep=""))
matplot(ls$W, YhatLoess, type="l", lty=1:length(span),
lwd=2, col=1:length(span), add=TRUE)
for(j in 1:length(span))
{
fit <- loess(Y ~ W, span=span[j], data=ls)
YhatLoess[,j] <- fit$fitted
LSRiskLoess[j] <- mean(fit$residuals^2)
pred <- predict(fit,data.frame(W=ts$W))
TSRiskLoess[j] <- mean((pred-ts$Y)^2, na.rm=TRUE)
}
plot(ls$W, ls$Y, xlim=c(-1.5, 1.5), ylim=c(-4, 6), xlab="W", ylab="Y",
main=paste("Mystery model: loess fits, span=", deparse(span), sep=""))
matplot(ls$W, YhatLoess, type="l", lty=1:length(span),
lwd=2, col=1:length(span), add=TRUE)
legend("topleft", paste("span=",span,sep=""), lty=1:length(span),
lwd=2, col=1:length(span), cex =1)
legend("topleft", paste("span=",span,sep=""), lty=1:length(span),
lwd=2, col=1:length(span), cex =0.5)
plot(ls$W, ls$Y, xlim=c(-1.5, 1.5), ylim=c(-4, 6), xlab="W", ylab="Y",
main=paste("Mystery model: loess fits, span=", deparse(span), sep=""))
matplot(ls$W, YhatLoess, type="l", lty=1:length(span),
lwd=2, col=1:length(span), add=TRUE)
legend("topleft", paste("span=",span,sep=""), lty=1:length(span),
lwd=2, col=1:length(span), cex =0.5)
span <- c(0.075, 0.1, 0.45,0.5,0.6, 0.9, 2)
# Create an empty matrix to store fitted Y for LS
YhatLoess <- matrix(NA, nrow(ls), length(span))
LSRiskLoess <- TSRiskLoess <- rep(NA,length(span))
for(j in 1:length(span))
{
fit <- loess(Y ~ W, span=span[j], data=ls)
YhatLoess[,j] <- fit$fitted
LSRiskLoess[j] <- mean(fit$residuals^2)
pred <- predict(fit,data.frame(W=ts$W))
TSRiskLoess[j] <- mean((pred-ts$Y)^2, na.rm=TRUE)
}
# loess fits
plot(ls$W, ls$Y, xlim=c(-1.5, 1.5), ylim=c(-4, 6), xlab="W", ylab="Y",
main=paste("Mystery model: loess fits, span=", deparse(span), sep=""))
matplot(ls$W, YhatLoess, type="l", lty=1:length(span),
lwd=2, col=1:length(span), add=TRUE)
legend("topleft", paste("span=",span,sep=""), lty=1:length(span),
lwd=2, col=1:length(span), cex =0.5)
max(LSRiskLoess)
max(TSRiskLoess)
min(TSRiskLoess)
min(LSRiskLoess)
matplot(span, cbind(LSRiskLoess,TSRiskLoess), ylim=c(0.1, 0.7),
xlab="span", ylab="Risk", type="p", pch=19, col=2:3, cex=1.5,
main=paste("Mystery model: Learning and test set risk for loess fits, span=",deparse(span),sep=""))
legend("topright", c("LS risk", "TS risk"), pch=19, col=2:3, cex=1.5)
legend("topright", c("LS risk", "TS risk"), pch=19, col=2:3, cex=0.5)
legend("topright", c("LS risk", "TS risk"), pch=19, col=2:3, cex=1)
matplot(span, cbind(LSRiskLoess,TSRiskLoess), ylim=c(0.1, 0.7),
xlab="span", ylab="Risk", type="p", pch=19, col=2:3, cex=1.5,
main=paste("Mystery model: Learning and test set risk for loess fits, span=",deparse(span),sep=""))
legend("topright", c("LS risk", "TS risk"), pch=19, col=2:3, cex=1)
matplot(span, cbind(LSRiskLoess,TSRiskLoess), ylim=c(0.1, 0.7),
xlab="span", ylab="Risk", type="p", pch=19, col=2:3, cex=1.5,
main=paste("Mystery model: Learning and test set risk for loess fits, span=",deparse(span),sep=""))
legend("topleft", c("LS risk", "TS risk"), pch=19, col=2:3, cex=0.7)
TSRiskLM
TSRiskLm
TSRiskLoess
D = 1:8
# create an empty list to store model for later
fitLm = vector("list", length(D))
# create an empty matrix to store fitted Y for training set
YhatLm.ts = matrix(NA, nrow(ts), length(D))
# create an empty matrix to store fitted Y for learning set
YhatLm.ls = matrix(NA, nrow(ls), length(D))
# create vectors of length(D) to store LS risk and TS risk for each model
LSRiskLm = rep(NA, length(D))
TSRiskLm = rep(NA, length(D))
w.ls = ls$W
w.ts = ts$W
W.ls = NULL
W.ts = rep(1,nrow(ts))
for(d in 1:length(D))
{
W.ls = cbind(W.ls, w.ls^D[d])
W.ts = cbind(W.ts, w.ts^D[d] )
fitLm[[d]] = lm(ls$Y ~ W.ls)
YhatLm.ts[,d] = W.ts %*% as.matrix(fitLm[[d]]$coef)
YhatLm.ls[,d] = fitLm[[d]]$fitted
LSRiskLm[d] = mean(fitLm[[d]]$residuals^2)
TSRiskLm[d] = mean((YhatLm.ts - ts$Y)^2, na.rm=TRUE)
}
# lm fits
plot(ls$W, ls$Y, xlim=c(-1.5, 1.5), ylim=c(-4, 6),
xlab="W", ylab="Y", main="Mystery model: lm fits, Y ~ 1 + W + ... + W^D")
matplot(ls$W, YhatLm.ls, type="l", lty=1:length(D), lwd=2,
col=1:length(D), add=TRUE)
legend("topleft", paste("D=",D,sep=""), lty=1:length(D),
lwd=2, col=1:length(D), cex = 0.5)
matplot(D, cbind(LSRiskLm,TSRiskLm), ylim=c(0.1, 1),
xlab="D", ylab="Risk", type="p", pch=19, col=2:3, cex=1.5,
main="Mystery model: Learning and test set risk for lm fits, Y ~ 1 + W + ... + W^D")
legend("topright", c("LS risk", "TS risk"), pch=19, col=2:3, cex=1)
lapply(fitLm, function(z) round(z$coefficients,2))
round(rbind(D, LSRiskLm, TSRiskLm), 4)
round(rbind(span, LSRiskLoess, TSRiskLoess), 4)
