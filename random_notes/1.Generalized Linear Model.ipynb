{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. Linear Regression\n",
    "2. Logistic Regression\n",
    "3. Lasso/Ridge/Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
    "\n",
    "f1.fit(X_train, y_train)\n",
    "\n",
    "coeficients = f1.coef_\n",
    "\n",
    "intercept = f1.intercept_\n",
    "\n",
    "y_test = f1.predict(X_test)\n",
    "\n",
    "R2 = f1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**:\t\n",
    "*fit_intercept* : boolean, optional\n",
    "whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered).\n",
    "\n",
    "*normalize* : boolean, optional, default False\n",
    "If True, the regressors X will be normalized before regression.\n",
    "\n",
    "*copy_X* : boolean, optional, default True\n",
    "If True, X will be copied; else, it may be overwritten.\n",
    "\n",
    "*n_jobs* : int, optional, default 1\n",
    "The number of jobs to use for the computation. If -1 all CPUs are used. This will only provide speedup for n_targets > 1 and sufficient large problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f2 = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \\\n",
    "                                     intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear',\\\n",
    "                                     max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Description of parameters](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)\n",
    "\n",
    "In a nutshell, one may choose the solver with the following rules:\n",
    "\n",
    "Case | Solver\n",
    "-----| ------\n",
    "Small dataset or L1 penalty | “liblinear”\n",
    "Multinomial loss | “lbfgs” or newton-cg”\n",
    "Large dataset | “sag”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f2.fit(X, y) #Fit the model according to the given training data.\n",
    "\n",
    "class_pred = f2.predict(X) # Predict class labels for samples in X.\n",
    "\n",
    "log_prob_pred = f2.predict_log_proba(X) # Log of probability estimates.\n",
    "\n",
    "prob_pred = f2.predict_proba(X) # Probability estimates.\n",
    "\n",
    "misclassification_rate = 1 - f2.score(X, y) # Returns the mean accuracy on the given test data and labels.\n",
    "\n",
    "coeficients = f2.coef_\n",
    "\n",
    "intercept = f2.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f2_2 = linear_model.LogisticRegressionCV(Cs=10, fit_intercept=True, cv=None, dual=False, penalty='l2', \\\n",
    "                                         scoring=None, solver='lbfgs', tol=0.0001, max_iter=100, class_weight=None, \\\n",
    "                                         n_jobs=1, verbose=0, refit=True, intercept_scaling=1.0, multi_class='ovr', \\\n",
    "                                         random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Description of parameters](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV)\n",
    "\n",
    "**cv** : integer or cross-validation generator\n",
    "\n",
    "The default cross-validation generator used is Stratified K-Folds. If an integer is provided, then it is the number of folds used. See the module sklearn.cross_validation module for the list of possible cross-validation objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lasso (L1) / Ridge (L2) / Elastic Net (L1, L2 combined) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3 = linear_model.Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000,\\\n",
    "                          tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3 = linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, \\\n",
    "                        solver='auto', random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3 = linear_model.ElasticNet(alpha=1.0, l1_ratio=0.5, fit_intercept=True, normalize=False, precompute=False, \\\n",
    "                             max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, \\\n",
    "                             random_state=None, selection='cyclic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Description of Lasso parameters](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso)\n",
    "\n",
    "[Description of Ridge parameters](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge)\n",
    "\n",
    "[Description of ElasticNet parameters](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet)\n",
    "\n",
    "**alpha : float, optional**\n",
    "\n",
    "Constant that multiplies the penalty term. Defaults to 1.0. alpha = 0 is equivalent to an ordinary least square, solved by the LinearRegression object. For numerical reasons, using alpha = 0 with the Lasso object is not advised and you should prefer the LinearRegression object.\n",
    "\n",
    "**l1_ratio : float**\n",
    "\n",
    "The ElasticNet mixing parameter, with 0 <= l1_ratio <= 1. For l1_ratio = 0 the penalty is an L2 penalty. For l1_ratio = 1 it is an L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3.fit(X_train, y_train)\n",
    "\n",
    "coeficients = f3.coef_\n",
    "\n",
    "intercept = f3.intercept_\n",
    "\n",
    "y_test = f3.predict(X_test)\n",
    "\n",
    "R2 = f3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3_2 = linear_model.LassoCV(eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, \\\n",
    "                            precompute='auto', max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, \\\n",
    "                            n_jobs=1, positive=False, random_state=None, selection='cyclic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3_2 = linear_model.RidgeCV(alphas=(0.1, 1.0, 10.0), fit_intercept=True, normalize=False, scoring=None, cv=None, \\\n",
    "                            gcv_mode=None, store_cv_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3_3 = linear_model.ElasticNetCV(l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, \\\n",
    "                                 normalize=False, precompute='auto', max_iter=1000, tol=0.0001, cv=None, copy_X=True, \\\n",
    "                                 verbose=0, n_jobs=1, positive=False, random_state=None, selection='cyclic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Description of LassoCV parameters](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV)\n",
    "\n",
    "[Description of RidgeCV parameters](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV)\n",
    "\n",
    "[Description of ElasticNetCV parameters](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV)\n",
    "\n",
    "**cv** : int, cross-validation generator or an iterable, optional\n",
    "Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
    "\n",
    "- None, to use the default 3-fold cross-validation,\n",
    "- integer, to specify the number of folds.\n",
    "- An object to be used as a cross-validation generator.\n",
    "- An iterable yielding train/test splits.\n",
    "\n",
    "For integer/None inputs, KFold is used.\n",
    "\n",
    "Refer User Guide for the various cross-validation strategies that can be used here.\n",
    "\n",
    "**alphas** : numpy array, optional\n",
    "\n",
    "List of alphas where to compute the models. If None alphas are set automatically\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
